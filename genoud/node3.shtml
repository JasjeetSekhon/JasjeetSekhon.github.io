<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 98.1 release (February 19th, 1998)
originally by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Normal Mixture Densities</TITLE>
<META NAME="description" CONTENT="Normal Mixture Densities">
<META NAME="keywords" CONTENT="genoud">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<LINK REL="STYLESHEET" HREF="genoud.css">
<LINK REL="next" HREF="node4.shtml">
<LINK REL="previous" HREF="node2.shtml">
<LINK REL="up" HREF="genoud.shtml">
<LINK REL="next" HREF="node4.shtml">
</HEAD>
<BODY >
<!--Navigation Panel-->
<A NAME="tex2html59"
 HREF="node4.shtml">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next_motif.gif"></A> 
<A NAME="tex2html57"
 HREF="genoud.shtml">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up_motif.gif"></A> 
<A NAME="tex2html51"
 HREF="node2.shtml">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="previous_motif.gif"></A>   
      <BODY TEXT="#000000" BGCOLOR="#FFFFFF" LINK="#0000EE" VLINK="#551A8B"
    ALINK="#FF0000">

 <A NAME="tex2html1"
 HREF="http://jsekhon.fas.harvard.edu">
<IMG
  ALIGN="BOTTOM" BORDER="0"
 SRC="http://data.fas.harvard.edu/jsekhon/pics/home.gif"
 ALT="http://data.fas.harvard.edu/jsekhon/pics/home.gif"></A>
<BR>
<B> Next:</B> <A NAME="tex2html60"
 HREF="node4.shtml">The Four-dimensional Hopf Model</A>
<B> Up:</B> <A NAME="tex2html58"
 HREF="genoud.shtml">Genetic Optimization Using Derivatives</A>
<B> Previous:</B> <A NAME="tex2html52"
 HREF="node2.shtml">Evolutionary Nonlinear Optimization</A>
<BR>
<BR>
<!--End of Navigation Panel-->

<H1><A NAME="SECTION00030000000000000000">
Normal Mixture Densities</A>
</H1>

<P>
Our first example of GENOUD involves finding maxima for three normal
mixture densities.  Because they have many local maxima, such
densities can be extremely difficult to optimize.  We run a Monte
Carlo sampling experiment to compare the performance of GENOUD with an
algorithm based on BFGS optimization from the best of many random
starting points.  The name of the modified BFGS algorithm that we
compare with GENOUD is enhanced BFGS (EBFGS).

<P>
The EBFGS first generates a large number of random starting values and
then runs the BFGS on the best one.The starting values are
  picked by drawing from a uniform distribution.  This is exactly how
  GENOUD determines its starting values.  This modification is an
improved implementation of what is often done to enhance the
performance of derivative based optimization systems.For
  instance, PROC NLIN of SAS provides an option for executing a grid
  search to choose a starting value.  Searching a very fine grid would
  match the performance of the random procedure.  But fine grid search
  does not readily scale up for multiple parameters.  The EBFGS, with
its multiple starting values, optimizes the mixture densities
significantly better than does the BFGS.  The BFGS implementation in
the EBFGS is the same as the one in GENOUD.  In both cases, the BFGS
uses the analytical first derivative.The use of a Newton
  algorithm does not significantly alter the results.  Newton methods
  are sometimes inferior.  Far from a maximum, methods which use the
  analytical Hessian--such as Newton methods--face significant
  problems because the analytical Hessian may not be positive
  definite.

<P>
The following three equations define the normal mixture densities we
use.  The first is known as the Claw density, the second as the
Asymmetric Double Claw and the third as the Discrete Comb density
(Marron and Wand 1992):
<BR>
<A NAME="eq:comb">&#160;</A><A NAME="eq:aclaw">&#160;</A><A NAME="eq:claw">&#160;</A><IMG
 WIDTH="614" HEIGHT="216" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="\begin{align}
f_{\text{C}} & =
\frac{1}{2}\mathrm{N}(0,1) +
\sum_{m=0}^{4} \fra...
...10} \frac{1}{21}\mathrm{N}\left(\frac{2m}{7},\frac{1}{21}\right)
\;.
\end{align}">
<BR>
In each equation, 
<!-- MATH: $\mathrm{N}(a,b)$ -->
N(<I>a</I>,<I>b</I>) denotes the normal density with
mean <I>a</I> and variance <I>b</I>.  The second and third of these densities
are particularly difficult to optimize.  Graphs of the densities
appear in Figures <A HREF="node6.shtml#fig:claw">1</A> through <A HREF="node6.shtml#fig:combclose">4</A>.

<P>
Each figure contains lines showing the path that GENOUD took to the
solution in an example run.  Because GENOUD's evolutionary algorithm
has stochastic components, other runs may follow different
paths.The path would be the same if the operator set,
  population size, starting values and pseudorandom number generator
  seeds were all the same.  What is most interesting is the way
GENOUD jumps among the local maxima in its search for the solution.
Unlike gradient based methods, GENOUD is not restricted to searching
just the concave region--i.e., near the peak--in which it started.
As can be seen in Figures <A HREF="node6.shtml#fig:aclaw">2</A>-<A HREF="node6.shtml#fig:combclose">4</A>, GENOUD
often jumps back and forth between concave regions.  This behavior
illustrates the fact that GENOUD accumulates and maintains information
about the whole parameter space.

<P>
Algorithms based solely on derivatives (Levenberg-Marquardt,
Newton-Raphson, quasi-Newton) cannot reliably find the global maxima
displayed in these figures.  Each of the densities has several local
maxima.  The discrete comb density, in Figures <A HREF="node6.shtml#fig:comb">3</A> and
<A HREF="node6.shtml#fig:combclose">4</A>, has a global maximum that exceeds the highest
local maximum only in the third decimal place.

<P>
For each of the three normal mixtures we run GENOUD and the EBFGS with
two different boundary conditions: narrow and wide.  The narrow
boundaries range from -3 to 3 and the wide ones from -20 to 20.
Figures <A HREF="node6.shtml#fig:claw">1</A>-<A HREF="node6.shtml#fig:comb">3</A> show the range within which the
densities are significantly positive.  In practice one rarely knows
where the solution is, and hence the case with the wide boundaries is
the most realistic.  We also manipulate the population size.  The
population refers to the number of random starts that we allow the
EBFGS to perform and to the number of trial solutions that GENOUD
employs.  We use a small population of 701 random starts (or trial
solutions) and a large population of 1402.  We execute 1000 Monte
Carlo replications for each combination of boundary width and
population size.  For each replication, we randomly draw starting
values from a uniform distribution defined on the interval between the
lower and upper boundary values.

<P>
Although we expect GENOUD to outperform the EBFGS, we do not expect
GENOUD to find the correct solution in all cases.  For any finite
number of generations, there is always a positive probability that
GENOUD will not find the correct solution.  As the Monte Carlo results
in Tables <A HREF="node7.shtml#tab:mix_small">2</A> and <A HREF="node7.shtml#tab:mix_large">3</A> show, that
probability is small for the mixture densities.  The probability that
GENOUD fails is far smaller than the failure rate of the EBFGS.

<P>
The Claw density (equation (<A HREF="node3.shtml#eq:claw">1</A>) and Figure <A HREF="node6.shtml#fig:claw">1</A>) is the
easiest of the three mixtures to maximize.  Regardless of the
population size or width of the boundaries, GENOUD always correctly
optimizes the function.  The EBFGS always correctly optimizes the
function only with the narrow boundaries.  When it has to contend with
the wide boundaries, its error rate rises sharply.  With the small
population of 701 random starts, the EBFGS gets the wrong answer in
24.4% of the replications.  With 1402 random starts the EBFGS still
fails 9.5% of the time.

<P>
The Asymmetric Double Claw (equation (<A HREF="node3.shtml#eq:aclaw">2</A>) and
Figure <A HREF="node6.shtml#fig:aclaw">2</A>) is a more difficult function.  With the small
population, GENOUD almost always finds the solution regardless of the
boundary width.  Its worst performance is an error rate of 0.9%,
which occurs with the small population and wide boundaries.  The EBFGS
again performs much worse than GENOUD, and worse than with the Claw
density.  The EBFGS's best result is an error rate of 12.4%, achieved
with the large population and narrow boundaries.  For this density,
the EBFGS's error rate ranges from 12 to 21 times as large as
GENOUD's.

<P>
The Discrete Comb density (equation (<A HREF="node3.shtml#eq:comb">3</A>) and Figures
<A HREF="node6.shtml#fig:comb">3</A>-<A HREF="node6.shtml#fig:combclose">4</A>) is also more difficult than the
Claw density to optimize.  GENOUD again finds the correct solution
almost all of the time, while the EBFGS performs even more poorly.
The worst performance for GENOUD is the error rate of 0.4% for the
small population and the wide boundaries.  The EBFGS's error rate
ranges from a low of 23.1% to a high of 88.7%.  When the EBFGS uses
the large population, its performance does improve but is still far
inferior to GENOUD with the <I>small</I> population.  To achieve the
inferior performance, the EBFGS consumes more time.

<P>
If the number of random starts were large enough, both GENOUD and the
EBFGS would almost always find the solution.  For fixed boundaries
that include the solution, the probability of each algorithm finding
the correct solution goes to 1.0 as the number of random starts goes
to infinity.  As the number of random starts increases, so does the
probability of having at least one starting value arbitrarily near the
correct mode of each density.  GENOUD, however, vastly outperforms the
EBFGS when both are given the same population.  GENOUD outperforms the
EBFGS even when the EBFGS is given twice the number of random starts.
The EBFGS takes significantly longer to run (2.5 to 4.9 times as
long), and yet performs dramatically worse than GENOUD.

<P>
In practice, people often run derivative-based systems with only a
handful of different starting values.  We find that even with a large
number of random starts, in half of the experimental conditions the
EBFGS has an error rate of over 19%.  There is no reason to believe
that other gradient-based optimization algorithms would perform
substantially better.  All such algorithms share the same
vulnerability.  They optimize locally.  They all climb the nearest
hill.  If the nearest hill is not the best one, the algorithms will
return the wrong answer.  Even derivative-based optimization with
multiple random starts is not reliable unless one has high confidence
about the location of the true solution or the problem is easy.  An
easy problem is one with an objective function which is globally
concave or one where the area of the concave neighborhood that
contains the solution is large relative to the area of the space being
searched.

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html59"
 HREF="node4.shtml">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next_motif.gif"></A> 
<A NAME="tex2html57"
 HREF="genoud.shtml">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up_motif.gif"></A> 
<A NAME="tex2html51"
 HREF="node2.shtml">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="previous_motif.gif"></A>   
      <BODY TEXT="#000000" BGCOLOR="#FFFFFF" LINK="#0000EE" VLINK="#551A8B"
    ALINK="#FF0000">
  <A NAME="tex2html1"
 HREF="http://data.fas.harvard.edu/jsekhon/">
<IMG
  ALIGN="BOTTOM" BORDER="0"
 SRC="http://data.fas.harvard.edu/jsekhon/pics/home.gif"
 ALT="http://data.fas.harvard.edu/jsekhon/pics/home.gif"></A>
<BR>
<B> Next:</B> <A NAME="tex2html60"
 HREF="node4.shtml">The Four-dimensional Hopf Model</A>
<B> Up:</B> <A NAME="tex2html58"
 HREF="genoud.shtml">Genetic Optimization Using Derivatives</A>
<B> Previous:</B> <A NAME="tex2html52"
 HREF="node2.shtml">Evolutionary Nonlinear Optimization</A>
<!--End of Navigation Panel-->
<ADDRESS>
<I>Jas S. Sekhon</I>
<BR><I>1998-07-30</I>
</ADDRESS>
</BODY>
</HTML>

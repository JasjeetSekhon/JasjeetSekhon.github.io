<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 98.1 release (February 19th, 1998)
originally by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Evolutionary Nonlinear Optimization</TITLE>
<META NAME="description" CONTENT="Evolutionary Nonlinear Optimization">
<META NAME="keywords" CONTENT="genoud">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<LINK REL="STYLESHEET" HREF="genoud.css">
<LINK REL="next" HREF="node3.shtml">
<LINK REL="previous" HREF="node1.shtml">
<LINK REL="up" HREF="genoud.shtml">
<LINK REL="next" HREF="node3.shtml">
</HEAD>
<BODY >
<!--Navigation Panel-->
<A NAME="tex2html49"
 HREF="node3.shtml">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next_motif.gif"></A> 
<A NAME="tex2html47"
 HREF="genoud.shtml">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up_motif.gif"></A> 
<A NAME="tex2html41"
 HREF="node1.shtml">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="previous_motif.gif"></A>   
      <BODY TEXT="#000000" BGCOLOR="#FFFFFF" LINK="#0000EE" VLINK="#551A8B"
    ALINK="#FF0000">

 <A NAME="tex2html1"
 HREF="http://jsekhon.fas.harvard.edu">
<IMG
  ALIGN="BOTTOM" BORDER="0"
 SRC="http://data.fas.harvard.edu/jsekhon/pics/home.gif"
 ALT="http://data.fas.harvard.edu/jsekhon/pics/home.gif"></A>
<BR>
<B> Next:</B> <A NAME="tex2html50"
 HREF="node3.shtml">Normal Mixture Densities</A>
<B> Up:</B> <A NAME="tex2html48"
 HREF="genoud.shtml">Genetic Optimization Using Derivatives</A>
<B> Previous:</B> <A NAME="tex2html42"
 HREF="node1.shtml">Introduction</A>
<BR>
<BR>
<!--End of Navigation Panel-->

<H1><A NAME="SECTION00020000000000000000">
Evolutionary Nonlinear Optimization</A>
</H1>

<P>
It is well known that nonlinear models can be extremely difficult to
optimize.  Problems of local optima or inherent discontinuities are
often compounded by the need to impose constraints on parameter values
to ensure that results are meaningful or feasible.  As Gill, Murray
and Wright observe, ``there is no guaranteed strategy that will
resolve every difficulty'' (1981, 285).

<P>
An evolutionary algorithm (EA) uses a collection of heuristic rules to
modify a population of trial solutions in such a way that each
generation of trial values tends to be on average better than its
predecessor.  The EA in GENOUD is intended to work for cases where a
solution is a vector of real numbers, each number being a value for a
scalar parameter of a function to be optimized.  Each heuristic rule,
or <I>operator</I>, acts on one or more trial solutions from the
current population to produce one or more trial solutions to be
included in the new population.  In order to find the global optimum
of a function, the EA portion of GENOUD does not need for derivatives
to exist or even for the function to be continuous.

<P>
The EA in GENOUD is fundamentally a genetic algorithm (GA) in which
the code-strings are vectors of floating point numbers rather than bit
strings, and the GA operators take special forms tuned for the
floating-point vector representation.  A GA uses a set of randomized
genetic operators to evolve a finite population of finite code-strings
over a series of generations (Holland 1975; Goldberg 1989;
Grefenstette and Baker 1989).  The operators used in GA
implementations vary (Davis 1991; Filho, Treleaven and Alippi 1994),
but in an analytical sense the basic set of operators can be defined
as reproduction, mutation, crossover and inversion.  The many
variations of these kinds reflect the variety of codes best suited for
different applications.  Reproduction entails selecting a code-string
with a probability that increases with the code-string's fitness
value.  Crossover and inversion use pairs or larger sets of the
selected code-strings to create new code-strings.  Mutation randomly
changes the values of elements of a single selected code-string.

<P>
Used in suitable combinations, the genetic operators tend to improve
the average fitness of each successive generation.  There is no
guarantee that the average fitness will improve between every pair of
successive generations.  The average fitness may well decline.  And in
general, the code-string with the greatest fitness in one generation
will not appear in the next one.In GENOUD, however, the
  code-string with the best fitness in one generation will appear in
  the next.  But theorems exist to prove that code-substrings that
have above average fitness values for the current population are
sampled at an exponential rate for inclusion in the subsequent
population (Holland 1975, 139-140).  As Grefenstette (1993, 77)
points out, however, such theorems describe only how a GA treats
individual substrings in the transition from one generation to the
next.  The theorems do not imply that GAs converge to global optima.
Each generation's population contains a biased sample of code-strings,
so that a substring's performance in that population is a biased
estimate of its average performance over all possible populations (De
Jong 1993; Grefenstette 1993).  The simple average of a substring's
performance in any one generation is therefore not in general a good
indication of how well the substring will perform over many
generations.

<P>
Better indications regarding the long-run properties of a GA can be
gained by thinking of the GA as a Markov chain.  A state of the chain
is a code-string population of the size used in the GA.  For
code-strings of finite length and GA populations of finite size, the
state space is finite.  If such a GA uses random reproduction and
random mutation, all states always have a positive probability of
occurring.  A finite GA with random reproduction and mutation is
therefore a finite and irreducible Markov chain.Feller
  (1970, 372-419) and Billingsley (1986, 107-142) review the
  relevant properties of Markov chains.  An irreducible, finite
Markov chain converges at an exponential rate to a unique stationary
distribution (Billingsley 1986, 128).  This means that the probability
that each population occurs rapidly converges to a constant, positive
value.  Nix and Vose (1992; Vose 1993) use a Markov chain model to
show that in a GA where the probability that each code-string is
selected to reproduce is proportional to its observed fitness, the
stationary distribution strongly emphasizes populations that contain
code-strings that have high fitness values.  They show that
asymptotically in the population size--i.e., in the limit for a
series of GAs with successively larger populations--populations that
have suboptimal average fitness have probabilities approaching zero in
the stationary distribution, while the probability for the population
that has optimal average fitness approaches one.  If <I>k</I>&gt;1 populations
have optimal average fitness, then in the limiting stationary
distribution the probability for each approaches 1/<I>k</I>.

<P>
The crucial practical implication from the theoretical results of Nix and Vose
is that a GA's success as an optimizer depends on having a sufficiently large
population of code-strings.  If the GA population is not sufficiently large,
then the Markov chain that the GA implements is converging to a stationary
distribution in which the probabilities of optimal and suboptimal states are
not sharply distinguished.  Suboptimal populations can be as likely or even
more likely to occur than optimal ones.  Because the Markov chain is
irreducible, the GA will necessarily generate an optimal code-string if it is
allowed to run for an unlimited number of generations.  But if the stationary
distribution is not favorable, the run time in terms of generations needed to
produce an optimal code-string will be excessive.  If <IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.gif"
 ALT="$\pi_j$">
is the
probability of an optimal code-string <I>s</I><SUB><I>j</I></SUB>, then the expected number of
generations until <I>s</I><SUB><I>j</I></SUB> occurs (from an arbitrary starting population) is
reasonably approximated by the recurrence time, 
<!-- MATH: $\mu_j = 1/\pi_j$ -->
<IMG
 WIDTH="80" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img4.gif"
 ALT="$\mu_j = 1/\pi_j$">
(Feller
1970, 393).  For all but trivially small state spaces, an unfavorable
stationary distribution can easily imply an expected running time in the
millions of generations.  But if the stationary distribution strongly
emphasizes optimal populations, relatively few generations may be needed to
find an optimal code-string.  In general, the probability of producing
an optimum in a fixed number of generations increases with the GA population
size.

<P>
In GENOUD, the probability that each <I>n</I>-dimensional parameter vector
is selected for reproduction is a tunable decreasing function of its
rank as determined by the value of the objective function: the
probability is 
<!-- MATH: $p=Q(1-Q)^{r-1}$ -->
<I>p</I>=<I>Q</I>(1-<I>Q</I>)<SUP><I>r</I>-1</SUP> where <IMG
 WIDTH="78" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$Q\in(0,1)$">
is the specified
tuning value and 
<!-- MATH: $r\in\{1,2,\dots,K\}$ -->
<IMG
 WIDTH="132" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.gif"
 ALT="$r\in\{1,2,\dots,K\}$">
is the rank of a vector from
the population of size <I>K</I>, with <I>r</I>=1 being the rank of the best
vector.  The best vector in each generation is carried over into the
next one.  All other vectors are replaced with the results from
application of eight operators that either mutate single vectors or
cross two or more vectors.

<P>
The eight operators are listed in Table 1.  The operators are in
small part based on the set of seven operators that Michalewicz (1992;
Michalewicz and Logan 1993; Michalewicz, Swaminathan and Logan 1993) used
in a program called
<A NAME="tex2html10"
 HREF="http://www.coe.uncc.edu/~gnazhiya/gchome.html">GENOCOP</A>
to solve linearly constrained nonlinear optimization problems with
real-valued parameters.  GENOUD was originally based on an early version of
GENOCOP.  However, the current version of GENOUD is <I>vastly</I>
different from GENOCOP.  The implementations of GENOUD's key algorithms are
original with us.  These include, but are not limited to, the
implementations of the operators, the pseudorandom number generator, the
rules for selecting individuals for reproduction and replacement, and
memory management.

<P>
In <I>uniform mutation</I>, <I>boundary mutation</I> and
<I>non-uniform mutation</I>, a single element of the selected vector is
chosen at random.  Uniform mutation changes the value of the element to a
value chosen from the uniform distribution on the interval between the
lower and upper bounds specified for the element.  Boundary mutation
replaces the element with one of the bounds.  Non-uniform mutation shrinks
the element toward one of the bounds, with the amount of shrinkage
decreasing as the generation count approaches the specified maximum number.
<I>Whole non-uniform mutation</I> does non-uniform mutation for all the
parameters in the vector.

<P>
One of the four crossover operators is used without change from
GENOCOP.  <I>Heuristic crossover</I> uses two vectors, 
<!-- MATH: $\mathbf{x}$ -->
<B>x</B>
and 
<!-- MATH: $\mathbf{y}$ -->
<B>y</B>, to produce a vector located at a random increment
from 
<!-- MATH: $\mathbf{x}$ -->
<B>x</B> in a direction pointing away from 
<!-- MATH: $\mathbf{y}$ -->
<B>y</B>.  The
other three crossover operators are new in GENOUD.  <I>Polytope
  crossover</I> computes one vector which is a convex combination of as
many vectors as there are parameters.  The input vectors are selected
with replacement from the current population.  Over generations this
operator works as a kind of randomized simplex or polytope search
method (Gill, Murray and Wright 1981, 94-95).  <I>Multiple point
  simple crossover</I> computes two vectors from two input vectors by
replacing a randomly selected set of elements with convex combinations
of the input vectors' values for those elements.
<I>Local-minimum crossover</I> computes a new vector in two steps.
First, starting from an input vector, it does a preset number of BFGS
iterations.  Then it computes a convex combination of the input vector
and the vector generated by the BFGS iterations.

<P>
If the parameter values that define the global optimum are within the
ranges over which GENOUD is allowed to search, GENOUD's EA operator
set is very good at finding a neighborhood of the global optimum
within which the objective function is concave (assuming the function
is concave at the optimum).  But the EA search operators can be quite
slow to move from an arbitrary point in that neighborhood to the
optimum point itself.  To expedite final convergence, GENOUD by
default applies BFGS optimization to the best trial solution in each
generation.  In place of analytical derivatives, the BFGS
optimizations can use built-in numerical derivatives based on optimal
intervals computed using algorithms described by Gill, Murray and
Wright (1981, 337-344).

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html49"
 HREF="node3.shtml">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next_motif.gif"></A> 
<A NAME="tex2html47"
 HREF="genoud.shtml">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up_motif.gif"></A> 
<A NAME="tex2html41"
 HREF="node1.shtml">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="previous_motif.gif"></A>   
      <BODY TEXT="#000000" BGCOLOR="#FFFFFF" LINK="#0000EE" VLINK="#551A8B"
    ALINK="#FF0000">
  <A NAME="tex2html1"
 HREF="http://data.fas.harvard.edu/jsekhon/">
<IMG
  ALIGN="BOTTOM" BORDER="0"
 SRC="http://data.fas.harvard.edu/jsekhon/pics/home.gif"
 ALT="http://data.fas.harvard.edu/jsekhon/pics/home.gif"></A>
<BR>
<B> Next:</B> <A NAME="tex2html50"
 HREF="node3.shtml">Normal Mixture Densities</A>
<B> Up:</B> <A NAME="tex2html48"
 HREF="genoud.shtml">Genetic Optimization Using Derivatives</A>
<B> Previous:</B> <A NAME="tex2html42"
 HREF="node1.shtml">Introduction</A>
<!--End of Navigation Panel-->
<ADDRESS>
<I>Jas S. Sekhon</I>
<BR><I>1998-07-30</I>
</ADDRESS>
</BODY>
</HTML>
